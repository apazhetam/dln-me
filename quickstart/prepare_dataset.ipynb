{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db4d876-b726-4ad0-bc29-1dfe74c84aea",
   "metadata": {},
   "source": [
    "#### In this notebook, we show how to prepare the training and test datasets for DLNs.\n",
    "\n",
    "#### The processed datasets and related information will be saved in the data/datasets/NAME/seed_{SEED}/data directory:\n",
    "- `train.csv` and `test.csv` (store features and the target class).\n",
    "- `data_info.json` (stores dataset information such as feature data types and scaling).\n",
    "\n",
    "#### The columns of the datasets should follow these standards:\n",
    "- Features should be ordered as categorical features, then continuous features, then the target.\n",
    "- Features should be scaled between 0 and 1.\n",
    "- The target column should be named “Target” and labeled from 0 up to (num_classes – 1).\n",
    "- Try to avoid using characters other than letters or underscores in feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b09d35-01c9-41b7-b3b3-ea9146dc07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "from data.data_utils import *\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e5e39b-2805-4a9c-ac98-79bbef2ab5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  3405  100  3405    0     0   5536      0 --:--:-- --:--:-- --:--:--  5536\n",
      "Archive:  example/data_raw/Heart/heart-disease-cleveland-uci.zip\n",
      "  inflating: example/data_raw/Heart/heart_cleveland_upload.csv  \n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "\n",
    "# Download the dataset ZIP to example/data_raw/Heart/\n",
    "!mkdir -p example/data_raw/Heart\n",
    "!curl -L -o example/data_raw/Heart/heart-disease-cleveland-uci.zip \\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/cherngs/heart-disease-cleveland-uci\n",
    "\n",
    "# Unzip\n",
    "!unzip -o example/data_raw/Heart/heart-disease-cleveland-uci.zip -d example/data_raw/Heart/\n",
    "!rm example/data_raw/Heart/heart-disease-cleveland-uci.zip\n",
    "\n",
    "# Read the .csv file\n",
    "datapath = 'example/data_raw/Heart/heart_cleveland_upload.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04151c1b-1249-4a4f-900b-ec874710115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eec00dc-dca9-469c-8bf5-44758109a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data shape: (293, 20)\n",
      "\n",
      "class distribution:\n",
      "Target\n",
      "0    159\n",
      "1    134\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing columns\n",
    "\n",
    "# Make categorical features one-hot\n",
    "# print('cp:', np.unique(df[\"cp\"], return_counts=True))\n",
    "# print('restecg:', np.unique(df[\"restecg\"], return_counts=True))\n",
    "# print('slope:', np.unique(df[\"slope\"], return_counts=True))\n",
    "# print('thal:', np.unique(df[\"thal\"], return_counts=True))\n",
    "# print('ca:', np.unique(df[\"ca\"], return_counts=True))\n",
    "\n",
    "df.drop(df[df[\"restecg\"]==1].index, inplace=True)\n",
    "oh_list = [\"cp\", \"restecg\", \"slope\", \"thal\", \"ca\"]\n",
    "for _f in oh_list:\n",
    "    df[_f] = df[_f].astype('object')\n",
    "one_hot_df = pd.get_dummies(df[oh_list], drop_first=True)\n",
    "df = df.drop(oh_list, axis=1)\n",
    "df = df.join(one_hot_df)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Assign the column name of the target feature as \"Target\"\n",
    "df.rename(columns={\"condition\":\"Target\"}, inplace=True)\n",
    "\n",
    "print('\\ndata shape: ', df.shape, sep='')\n",
    "print('\\nclass distribution:\\n', df.Target.value_counts(), sep='')\n",
    "# print('\\ncolumn types:\\n', df.dtypes, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c65fe1-d06e-41ad-84a3-35565038ffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous_features: ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
      "\n",
      "categorical_features: ['sex', 'fbs', 'exang', 'cp_1', 'cp_2', 'cp_3', 'restecg_2', 'slope_1', 'slope_2', 'thal_1', 'thal_2', 'ca_1', 'ca_2', 'ca_3']\n"
     ]
    }
   ],
   "source": [
    "# Sort features into the [categorical, continuous, target] order\n",
    "\n",
    "continuous_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(continuous_features))\n",
    "print('continuous_features:', continuous_features)\n",
    "print('\\ncategorical_features:', categorical_features)\n",
    "\n",
    "# Reindex columns to [cat, con, label]\n",
    "df = df.reindex(columns=categorical_features+continuous_features+['Target'], copy=False)\n",
    "\n",
    "dtype_dict = df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac38649a-6712-42fa-9b90-a90a79de1abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (219, 20)\n",
      "(array([0, 1]), array([119, 100]))\n",
      "\n",
      "test: (74, 20)\n",
      "(array([0, 1]), array([40, 34]))\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split data into train/(val)/test\n",
    "seed = 0\n",
    "\n",
    "train_fraction = 0.75 ###\n",
    "df_train, df_test = shuffle_split_data(df, train_fraction, seed=seed)\n",
    "\n",
    "print('train:', df_train.shape)\n",
    "print(np.unique(df_train.Target, return_counts=True))\n",
    "print('\\ntest:', df_test.shape)\n",
    "print(np.unique(df_test.Target, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a702d1-d16a-4bf6-9e6b-3dd8d2c6cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of the training data\n",
    "\n",
    "# ncol, nrow = 2, int(np.ceil(len(df_train.columns)/2))\n",
    "# figsize = (16,3*nrow)\n",
    "\n",
    "# plot_hist(df_train, figsize, nrow, ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995dae9c-6d3f-47bd-b476-37ec7f181d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/bjv40z8521q11wbgdyzq7pgw0000gn/T/ipykernel_12557/978047173.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '34.09' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_train.loc[df_train[feature]<lower, feature] = lower\n",
      "/var/folders/mv/bjv40z8521q11wbgdyzq7pgw0000gn/T/ipykernel_12557/978047173.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '34.09' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_test.loc[df_test[feature]<lower, feature] = lower\n",
      "/var/folders/mv/bjv40z8521q11wbgdyzq7pgw0000gn/T/ipykernel_12557/978047173.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '131.9' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_train.loc[df_train[feature]<lower, feature] = lower\n",
      "/var/folders/mv/bjv40z8521q11wbgdyzq7pgw0000gn/T/ipykernel_12557/978047173.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '131.9' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_test.loc[df_test[feature]<lower, feature] = lower\n",
      "/var/folders/mv/bjv40z8521q11wbgdyzq7pgw0000gn/T/ipykernel_12557/978047173.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '88.18' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_train.loc[df_train[feature]<lower, feature] = lower\n",
      "/var/folders/mv/bjv40z8521q11wbgdyzq7pgw0000gn/T/ipykernel_12557/978047173.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '88.18' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_test.loc[df_test[feature]<lower, feature] = lower\n"
     ]
    }
   ],
   "source": [
    "# Feature outlier clipping and [0, 1] scaling\n",
    "\n",
    "for feature in continuous_features:\n",
    "    lower = np.percentile(df_train[feature], 0.5)\n",
    "    upper = np.percentile(df_train[feature], 99.5)\n",
    "\n",
    "    df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "    df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "    df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "    df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "\n",
    "scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "feature_list = [continuous_features, categorical_features]\n",
    "df_train_scaled, df_test_scaled, scaler_params = scale_features(df_train, df_test, feature_list, scaler_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c6ace1e-3368-47fd-a5cc-061f7785b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scaled training data\n",
    "\n",
    "# plot_hist(df_train_scaled, figsize, nrow, ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1652e590-5ec6-4d14-a420-0336ae0438ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data and feature information\n",
    "\n",
    "# Save data into the data/datasets/Heart/seed_0/data directory\n",
    "# scaler_params and dtype_dict are used for network visualization\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "folderpath = f'{parent_dir}/data/datasets/Heart/seed_{seed}/data'\n",
    "save_data(folderpath, continuous_features, categorical_features, scaler_params, dtype_dict, df_train_scaled, df_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d23907-9ba6-4ca8-9443-91b9a4d1332f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dln-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
